================================================================================
JOB SHOP SCHEDULING ML APPROXIMATION - PROJECT INDEX
================================================================================

QUICK START:
    1. Install dependencies:    pip install -r requirements.txt --break-system-packages
    2. Run demo:               python demo.py
    3. Train with your data:   python main.py

MAIN DOCUMENTS:
    üìÑ PROJECT_SUMMARY.md      Complete overview, architecture, workflows
    üìÑ README.md               Detailed usage guide and API reference

CORE MODULES (Run these):
    üöÄ main.py                 Full training pipeline (data ‚Üí train ‚Üí evaluate)
    üéÆ demo.py                 Quick demo with synthetic data (no files needed)

CONFIGURATION:
    ‚öôÔ∏è  config.py              All hyperparameters, weights, paths
                               ‚Üí Edit this to customize behavior

DATA PIPELINE:
    üìä data_loader.py          Load Excel files, create instances
    üéØ mip_oracle.py           Solve with Gurobi (generate training labels)
    üìà dataset.py              Generate PyTorch datasets

MODEL ARCHITECTURE:
    üß† gnn_model.py            Graph Neural Network policy
    üîó graph_builder.py        Convert schedules to graph representation

TRAINING:
    üèãÔ∏è  training.py            Imitation learning trainer
    üé≤ rl_env.py               RL environment (skeleton for future)

EVALUATION:
    üìä evaluation.py           Compare ML vs MIP vs heuristics

DEPENDENCIES:
    üì¶ requirements.txt        Python packages to install

================================================================================
TYPICAL WORKFLOWS:
================================================================================

1Ô∏è‚É£  FIRST TIME SETUP:
    python demo.py                           # Verify installation
    # Place your Excel files: islem_tam_tablo.xlsx, bold_islem_sure_tablosu.xlsx
    python main.py                           # Train model (~10-30 minutes)

2Ô∏è‚É£  AFTER INITIAL TRAINING:
    python main.py --skip-dataset-generation  # Reuse cached data
    python main.py --skip-training            # Just evaluate existing model

3Ô∏è‚É£  HYPERPARAMETER TUNING:
    # Edit config.py (change learning rate, batch size, etc.)
    python main.py --skip-dataset-generation --num-epochs 50

4Ô∏è‚É£  PRODUCTION EVALUATION:
    python main.py --skip-training \
        --n-eval-instances 100 \
        --eval-max-jobs 20 \
        --compare-with-mip

================================================================================
KEY CONFIGURATION (edit config.py):
================================================================================

OBJECTIVE WEIGHTS (adjust scheduling priorities):
    w_MS   = 0.2    # Makespan importance
    w_T    = 0.5    # Tardiness importance
    w_row  = 0.1    # Precedence waiting
    w_asm  = 0.1    # Assembly waiting
    w_gap  = 0.1    # Machine idle gaps

DATASET GENERATION:
    N_TRAIN_INSTANCES = 100         # Training instances
    MIN_JOBS_PER_INSTANCE = 3       # Minimum jobs per instance
    MAX_JOBS_PER_INSTANCE = 8       # Maximum jobs per instance
    MIP_TIME_LIMIT = 300            # Gurobi time limit (seconds)

TRAINING:
    learning_rate = 0.001           # Learning rate
    batch_size = 8                  # Batch size
    num_epochs = 100                # Training epochs
    patience = 15                   # Early stopping patience

MODEL:
    hidden_dim = 128                # Hidden dimension
    num_gnn_layers = 3              # Number of GNN layers
    use_attention = True            # Use attention (GAT)

================================================================================
FILE PURPOSES:
================================================================================

config.py           ‚Üí Central configuration hub
data_loader.py      ‚Üí SchedulingInstance class, load Excel data
mip_oracle.py       ‚Üí MIPOracle class, solve with Gurobi
graph_builder.py    ‚Üí GraphBuilder class, create graph representations
dataset.py          ‚Üí SchedulingDataset class, generate training data
gnn_model.py        ‚Üí SchedulingGNN class, neural network policy
training.py         ‚Üí ImitationTrainer class, train the model
rl_env.py           ‚Üí JobShopEnv class, RL simulation (future)
evaluation.py       ‚Üí Evaluator class, compare methods
main.py             ‚Üí Main pipeline orchestration
demo.py             ‚Üí Demonstration with synthetic data
README.md           ‚Üí Comprehensive documentation
PROJECT_SUMMARY.md  ‚Üí High-level overview
requirements.txt    ‚Üí Python dependencies
INDEX.txt           ‚Üí This file

================================================================================
COMMAND LINE OPTIONS (python main.py --help):
================================================================================

Data:
    --islem-tam-path PATH       Path to islem_tam_tablo.xlsx
    --bold-sure-path PATH       Path to bold_islem_sure_tablosu.xlsx

Pipeline Control:
    --skip-data-loading         Skip loading Excel files
    --skip-dataset-generation   Use cached datasets
    --skip-training             Load pre-trained model
    --skip-evaluation           Skip evaluation

Training:
    --batch-size INT            Batch size (default: 8)
    --num-epochs INT            Training epochs (default: 100)
    --checkpoint-dir PATH       Model checkpoint directory
    --cpu                       Force CPU (disable CUDA)

Evaluation:
    --n-eval-instances INT      Number of test instances
    --eval-min-jobs INT         Min jobs per test instance
    --eval-max-jobs INT         Max jobs per test instance
    --compare-with-mip          Include MIP in comparison (slow)

================================================================================
OUTPUT STRUCTURE:
================================================================================

After running main.py, you will have:

dataset_cache/              # Reusable cached datasets
    ‚îú‚îÄ‚îÄ train.pkl           # Training samples
    ‚îú‚îÄ‚îÄ val.pkl             # Validation samples
    ‚îî‚îÄ‚îÄ test.pkl            # Test samples

checkpoints/                # Saved models
    ‚îú‚îÄ‚îÄ best_model.pt       # Best validation model ‚≠ê
    ‚îú‚îÄ‚îÄ final_model.pt      # Final epoch model
    ‚îú‚îÄ‚îÄ training_history.json   # Loss/accuracy curves
    ‚îî‚îÄ‚îÄ training_curves.png     # Visualization

================================================================================
PERFORMANCE EXPECTATIONS:
================================================================================

Training Time:
    - Small dataset (20 instances, 3-5 jobs): ~5 minutes
    - Medium dataset (100 instances, 3-8 jobs): ~20-40 minutes
    - Large dataset (200 instances, 5-10 jobs): ~1-2 hours

Inference Time:
    - Small instance (3-5 jobs): <0.1 seconds
    - Medium instance (8-10 jobs): ~0.2 seconds
    - Large instance (15-20 jobs): ~0.5 seconds

Quality (Optimality Gap vs MIP):
    - After good training: 5-15%
    - Better than SPT heuristic by: 20-40%

================================================================================
TROUBLESHOOTING:
================================================================================

Problem: "Gurobi license not found"
‚Üí Install Gurobi and obtain license (free for academics)
‚Üí Set environment: export GRB_LICENSE_FILE=/path/to/gurobi.lic

Problem: "Data files not found"
‚Üí Update paths in config.py or use --islem-tam-path
‚Üí Ensure BOLD_FLAG column exists

Problem: "CUDA out of memory"
‚Üí Use --cpu flag
‚Üí Reduce batch_size in config.py
‚Üí Use smaller model (reduce hidden_dim)

Problem: "Training accuracy stuck at 0"
‚Üí Check MIP solver is finding solutions
‚Üí Verify dataset generation succeeded
‚Üí Try lower learning rate (0.0001)

Problem: "Model not improving"
‚Üí Train longer (more epochs)
‚Üí Generate more training data
‚Üí Increase model size

================================================================================
CONTACT & SUPPORT:
================================================================================

üìö Documentation:   README.md (detailed), PROJECT_SUMMARY.md (overview)
üéÆ Demo:            python demo.py
üîß Issues:          Check error messages, verify Gurobi license
üí° Tips:            Start with demo.py, then small datasets, then scale up

================================================================================
VERSION: 1.0 | CREATED: November 2024 | LICENSE: MIT
================================================================================
