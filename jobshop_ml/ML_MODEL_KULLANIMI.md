# ML Model KullanÄ±mÄ±

## ğŸ” Durum

**Åu ana kadar**: Sadece MIP Solver (Gurobi) kullandÄ±k
**ML Model**: HenÃ¼z eÄŸitilmedi, kullanÄ±lamÄ±yor

## ğŸ“Š Ä°ki Sistem KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Ã–zellik | MIP Solver (Gurobi) | ML Model (GNN) |
|---------|---------------------|----------------|
| **HÄ±z** | YavaÅŸ (dakikalar) | HÄ±zlÄ± (saniyeler) |
| **Kalite** | Optimal/Feasible | MIP'ten %5-15 daha kÃ¶tÃ¼ |
| **EÄŸitim** | Gerekmez | Gerekir |
| **KullanÄ±m** | âœ… Åu anda kullanÄ±yoruz | âŒ HenÃ¼z eÄŸitilmedi |

## ğŸš€ ML Modeli EÄŸitmek Ä°Ã§in

### AdÄ±m 1: ML Modeli EÄŸit

```bash
cd /Users/derinegeevren/BIG_TEST/jobshop_ml
python main.py --num-epochs 50 --batch-size 8
```

Bu komut:
1. MIP solver ile kÃ¼Ã§Ã¼k Ã¶rnekler Ã§Ã¶zer (training data)
2. GNN modelini eÄŸitir
3. Modeli `checkpoints/best_model.pt` olarak kaydeder

### AdÄ±m 2: EÄŸitilmiÅŸ Modeli Kullan

```python
from gnn_model import SchedulingGNN
from evaluation import MLScheduler
from graph_builder import GraphBuilder
from core import DataLoader, create_instance
import torch

# Veri yÃ¼kle
loader = DataLoader()
loader.load_data()
instance = create_instance(loader)

# EÄŸitilmiÅŸ modeli yÃ¼kle
model = SchedulingGNN()
checkpoint = torch.load('checkpoints/best_model.pt')
model.load_state_dict(checkpoint['model_state_dict'])

# ML scheduler oluÅŸtur
scheduler = MLScheduler(model, GraphBuilder(), device='cpu')

# HÄ±zlÄ± Ã§Ã¶zÃ¼m!
result = scheduler.schedule(instance)
print(f"Makespan: {result['makespan']:.2f} dakika")
print(f"Objective: {result['objective']:.2f}")
```

## âš¡ ML Modelin AvantajlarÄ±

1. **HÄ±z**: MIP 300 saniye â†’ ML <1 saniye
2. **BÃ¼yÃ¼k Problemler**: MIP Ã§Ã¶zemezken ML Ã§Ã¶zebilir
3. **Production**: GerÃ§ek zamanlÄ± Ã§Ã¶zÃ¼m iÃ§in ideal

## ğŸ“ Ã–zet

- âœ… **MIP Solver**: KullanÄ±yoruz, optimal Ã§Ã¶zÃ¼m
- âŒ **ML Model**: HenÃ¼z eÄŸitilmedi
- ğŸ¯ **Sonraki AdÄ±m**: `python main.py` ile ML modeli eÄŸit

## ğŸ”„ Ä°ki Sistemi Birlikte Kullanmak

```python
# KÃ¼Ã§Ã¼k problemler iÃ§in: MIP (optimal)
# BÃ¼yÃ¼k problemler iÃ§in: ML (hÄ±zlÄ±)

if len(instance.operations) < 50:
    # MIP kullan
    solution = solver.solve(model, instance)
else:
    # ML kullan
    result = ml_scheduler.schedule(instance)
```



